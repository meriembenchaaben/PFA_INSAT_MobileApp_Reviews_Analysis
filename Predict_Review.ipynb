{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict Review.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W4tegu5cB_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "pd.options.mode.chained_assignment = None\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpmYURHtcSuC",
        "colab_type": "code",
        "outputId": "08a7df2b-03c9-4801-dfea-b77a50e4384d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IdfDBPldIe6",
        "colab_type": "code",
        "outputId": "3a1c27ff-3af0-4a32-cda7-21b92fe87319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "pip install -U emoji"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 928kB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=d02c453688ad0ce92ec96109af565f6209ca383cbfb81f0f442c262226a0190e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a56ZEgBScfyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exclude = set(string.punctuation) \n",
        "import re\n",
        "def remove_punctuation(x): \n",
        "  \"\"\" Helper function to remove punctuation from a string x: any string \"\"\"\n",
        "  try: \n",
        "    x= re.sub(r\"[-+]?[0-9]+(\\.[0-9]+)?\",\"\",x)\n",
        "    y = ''.join(ch for ch in x if ch not in exclude) \n",
        "  except:\n",
        "    pass \n",
        "  return y \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2JcKwtycsjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap-t5wPNcxoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
        "def remove_emoji(string):\n",
        "    string=str(string)\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4QYdTbcc08Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emoji\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijNY-FqfiDO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STOPWORDS = set({'an', \"you'll\", \"it's\", 'each', 'at', 'ain', \"mustn't\", 'we', 'mightn', 'here', 'from', 'he', 'between', 'no', \"haven't\", 'to', 'how', \"aren't\", 'wouldn', 'didn', 'same', 'won', \"should've\", 'isn', 'both', 'did', 'weren', 'a', \"wouldn't\", 'ourselves', \"you've\", 'i', 'such', 'is', 'don', 'them', 'this', 'mustn', 'your', 'further', 'which', 'should', 'himself', 'over', 'most', 'out', 'does', 'am', 'those', 'by', \"shouldn't\", 'do', 'shouldn', 'be', 'there', \"that'll\", \"won't\", \"shan't\", 'own', \"doesn't\", 'ma', \"isn't\", 'all', 'then', 'she', 'hers', 'until', 'after', 'but', 've', 'our', 'if', 'about', 'can', 'her', 'these', 'again', \"hasn't\", 'nor', 'him', \"you'd\", 'where', 'with', \"she's\", 'on', 'of', 'other', 'very', 'ours', 'during', 't', 'had', 'because', \"weren't\", 'yourselves', 'than', \"hadn't\", 'me', 'doing', 'against', 'now', 'doesn', 'wasn', 'too', 'you', 'what', 'd', 're', \"didn't\", 'myself', 'his', \"needn't\", 'are', 'under', 'off', 'herself', 'up', 'some', 'itself', 'been', 'were', 'through', 'when', 'as', 'for', 'who', 'theirs', 'so', 'below', 'll', 'hadn', 'shan', 'any', 'its', 'and', 'in', \"mightn't\", 'before', 'while', 'that', 'has', 'yours', 'it', 'down', 'my', 'whom', 'their', 'few', \"couldn't\", 'hasn', 'why', \"you're\", 'or', 'haven', 'needn', 's', \"don't\", 'couldn', 'above', 'm', 'being', 'only', 'y', 'will', 'the', 'once', 'into', 'having', 'aren', 'more', 'themselves', 'have', 'just', 'o', 'was', \"wasn't\", 'they', 'not', 'yourself'})\n",
        "#print(STOPWORDS)\n",
        "#def remove_stopwords(text):\n",
        "#    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "#    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_A0jLPcdQjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(subject,body):\n",
        "  \n",
        "  review= subject +\" \"+ body\n",
        "  review= review.lower()\n",
        "  review= remove_emoji(review)\n",
        "  review = remove_punctuation(review)\n",
        "  #review = remove_stopwords(review)\n",
        "  review =stem_words(review)\n",
        "  return review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upyb_VOagsDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68d0480a-188d-466e-b65e-b0b323f73a10"
      },
      "source": [
        "from keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "def f1_loss(y_true, y_pred):\n",
        "    \n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return 1 - K.mean(f1)\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfiFKv1fJVy",
        "colab_type": "code",
        "outputId": "8b3e6ec3-ba8a-41ce-e108-dd86685b06c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model=keras.models.load_model(\"gdrive/My Drive/All reviews/ModelNoBugsFinal.h5\", custom_objects={'f1': f1,'precision':precision,'recall':recall})"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opDm-Wo4kZ7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=['Advertising' ,'Battery'  ,'Camera & Photos' ,'Complexity',\n",
        " 'Connectivity & HDMI', 'Customer Support', 'Design & UX' ,'Devices',\n",
        " 'Feature Requests' ,'Frequency', 'Gaming', 'Import Export',\n",
        " 'Internationalization', 'Location Services' ,'Notifications & Alerts',\n",
        " 'Operating System' ,'Performance' ,'Pricing & Payment' ,'Privacy',\n",
        " 'Security & Accounts', 'Sign Up & Login', 'Social & Collaboration',\n",
        " 'Streaming & Video & Audio' ,'Update']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sakKJFyjeisl",
        "colab_type": "code",
        "outputId": "27e2010b-51a2-49ae-a74d-aeb3ef1f8149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "subject = input(\"Subject = \")\n",
        "body= input (\"Body = \")\n",
        "review = preprocessing(subject=subject,body=body) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Subject = the video is not working\n",
            "Body = can someone help me with that \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auyj_UPZ3Lxa",
        "colab_type": "code",
        "outputId": "aa60745c-dc5c-4cf3-f84b-54ee817e6137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (review)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the video is not work can someon help me with that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWZ1ALOOed2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = TfidfTransformer()\n",
        "loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"gdrive/My Drive/All reviews/feature.pkl\", \"rb\")))\n",
        "tfidfReview = transformer.fit_transform(loaded_vec.fit_transform(np.array([review])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNQlbnob7xq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict (model,review): \n",
        "  mask = model.predict(tfidfReview.toarray())>0.3\n",
        "  x=np.array(classes)[mask[0]]\n",
        "\n",
        "  if len(x)==0 :\n",
        "    if np.max(np.array(model.predict(tfidfReview.toarray()))) > 0.2 :\n",
        "      return [classes[np.argmax(np.array(model.predict(tfidfReview.toarray())))]]\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nCeKblPLNsg",
        "colab_type": "code",
        "outputId": "09913c3a-d01b-4d02-d7b0-3d64952990f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(predict(model,tfidfReview))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Customer Support' 'Streaming & Video & Audio']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkmfQodrOOjP",
        "colab_type": "code",
        "outputId": "f256fce8-c623-410f-b3c0-4ac345712a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(model.predict(tfidfReview.toarray()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.9460611e-04 1.6686320e-04 1.3228655e-03 7.8725815e-04 1.4264047e-02\n",
            "  9.8918104e-01 9.9847913e-03 1.8669665e-03 7.6290965e-04 9.0557337e-04\n",
            "  4.2457283e-03 1.2107503e-04 1.6973913e-03 1.8116832e-04 1.3498366e-03\n",
            "  2.1812320e-04 4.8539042e-03 1.7830729e-04 4.6828389e-04 3.5133140e-05\n",
            "  1.3640314e-02 4.2149425e-04 9.9694687e-01 4.4902563e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGmmS_B1jUc6",
        "colab_type": "code",
        "outputId": "85fb4c41-501c-4100-e914-4afa0f77e155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mask = model.predict(tfidfReview.toarray())>0.3\n",
        "print (np.array(classes)[mask[0]])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Customer Support' 'Streaming & Video & Audio']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}